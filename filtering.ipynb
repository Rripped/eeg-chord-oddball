{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing and Filtering of Chord-Oddball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "import ccs_eeg_utils\n",
    "import numpy as np\n",
    "import mne.preprocessing as prep\n",
    "import os\n",
    "import sklearn \n",
    "from contextlib import contextmanager\n",
    "from autoreject import AutoReject\n",
    "import json\n",
    "\n",
    "from mne_bids import (BIDSPath, read_raw_bids, write_raw_bids, inspect_dataset)\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# path where dataset is stored\n",
    "bids_root = \"./data/ds003570/\"\n",
    "TASK = 'AuditoryOddballChords'\n",
    "SUBJECT = '014'\n",
    "SUPRESS_BIDS_OUTPUT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager to suppress stdout and stderr\n",
    "@contextmanager\n",
    "def suppress_stdout_stderr():\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "def read_raw_data(subject_id):\n",
    "    bids_path = BIDSPath(subject=subject_id,\n",
    "                         datatype='eeg', suffix='eeg', task=TASK,\n",
    "                         root=bids_root)\n",
    "\n",
    "    if SUPRESS_BIDS_OUTPUT:\n",
    "        with suppress_stdout_stderr():\n",
    "            raw = read_raw_bids(bids_path)\n",
    "    else:\n",
    "        raw = read_raw_bids(bids_path)\n",
    "\n",
    "    # Inplace?\n",
    "    ccs_eeg_utils.read_annotations_core(bids_path, raw)\n",
    "    raw.load_data()\n",
    "    \n",
    "    return raw, bids_path\n",
    "\n",
    "def preprocessing(raw, bad_channels = []):\n",
    "    # TODO: bandpass first, downsample later? -> expensive!\n",
    "    # 1. Downsampling to 64 Hz\n",
    "    if raw.info['sfreq'] > 64:\n",
    "        raw.resample(128)\n",
    "\n",
    "    # Set channel types to EEG if not already set\n",
    "    if not all(ch_type in ['eeg', 'stim'] for ch_type in raw.get_channel_types()):\n",
    "        eeg_channel_names = raw.ch_names\n",
    "        channel_types = {name: 'eeg' for name in eeg_channel_names}\n",
    "        raw.set_channel_types(channel_types)\n",
    "\n",
    "    # 2. Band-pass filter between 0.5 Hz and 30 Hz\n",
    "    raw.filter(0.5, 30, fir_design='firwin')\n",
    "\n",
    "    # 3. Re-referencing to the average activity of all electrodes\n",
    "    #TODO: add apply_proj() here to apply arp?\n",
    "    raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "    \"\"\" events = prep.find_eog_events(raw)\n",
    "    print(events) \"\"\"\n",
    "\n",
    "    # 5. Data Reduction (optional)\n",
    "    # For instance, crop the first 60 seconds of the data\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def save_preprocessed_data(file_path, raw):\n",
    "    \"\"\"\n",
    "    Saves the preprocessed EEG data to a file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path where the preprocessed data will be saved.\n",
    "    raw (mne.io.Raw): The preprocessed MNE Raw object containing EEG data.\n",
    "    \"\"\"\n",
    "    # Check if file_path ends with .fif extension\n",
    "    if not file_path.endswith('.fif'):\n",
    "        file_path += '.fif'\n",
    "\n",
    "    # Save the data\n",
    "    try:\n",
    "        raw.save(file_path, overwrite=True)\n",
    "        print(f\"Data saved successfully to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data: {e}\")\n",
    "\n",
    "# see https://neuraldatascience.io/7-eeg/erp_artifacts.html\n",
    "def get_ica(data):\n",
    "    data.set_montage('standard_1020', match_case=False)\n",
    "    ica = mne.preprocessing.ICA(method=\"fastica\")\n",
    "    blocks = split_in_blocks(data.copy())\n",
    "    for block in blocks:\n",
    "        ica.fit(block, verbose=True)\n",
    "        #ica.plot_components()\n",
    "        ica.plot_properties(block)\n",
    "    # components to be excluded\n",
    "    # add python input to determine which components to exclude\n",
    "    input_str = input(\"Enter index of the components to be separated by space: \")  \n",
    "    # Converting input string to a list of integers  \n",
    "    exclude_components = input_str.split()  \n",
    "    exclude_components = [int(num) for num in exclude_components]  \n",
    "  \n",
    "    # Printing the list  \n",
    "    print(\"List of components:\", exclude_components) \n",
    "    ica.exclude = exclude_components\n",
    "    reconst_raw = data.copy()\n",
    "    # apply with excluded components\n",
    "    ica.apply(reconst_raw)\n",
    "    \n",
    "    # TODO: add finf_bads_ of mne.ICA?\n",
    "    return ica\n",
    "\n",
    "\n",
    "def split_in_blocks(raw):\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Identify indices of 'STATUS:boundary' events\n",
    "    boundary_events = events[events[:, 2] == event_id['STATUS:boundary'], 0]\n",
    "\n",
    "    # Split the data into blocks\n",
    "    blocks = []\n",
    "    start_idx = 0\n",
    "    for end_idx in boundary_events:\n",
    "        block = raw.copy().crop(tmin=raw.times[start_idx], tmax=raw.times[end_idx])\n",
    "        blocks.append(block)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def interpolate_bads_and_merge(blocks):\n",
    "    # Interpolate bad channels\n",
    "    for block in blocks:\n",
    "        block.interpolate_bads()\n",
    "\n",
    "    # Merge the blocks\n",
    "    raw = mne.concatenate_raws(blocks)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def create_bad_json_structure():\n",
    "    subjects = [i for i in range(1,41)]\n",
    "    for s in range(len(subjects)):\n",
    "        subjects[s] = [b for b in range(1,9)]\n",
    "        for b in range(len(subjects[s])):\n",
    "            subjects[s][b] = []\n",
    "\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 4818943  =      0.000 ...  2353.000 secs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "            <td>sub-014</td>\n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>3 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>2048.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>1024.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 10 non-empty values\n",
       " bads: []\n",
       " ch_names: Fp1, AF7, AF3, F1, F3, F5, F7, FT7, FC5, FC3, FC1, C1, C3, C5, ...\n",
       " chs: 64 misc\n",
       " custom_ref_applied: False\n",
       " dig: 3 items (3 Cardinal)\n",
       " highpass: 0.0 Hz\n",
       " line_freq: 60.0\n",
       " lowpass: 1024.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 64\n",
       " projs: []\n",
       " sfreq: 2048.0 Hz\n",
       " subject_info: 5 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw, bids_path = read_raw_data(SUBJECT)\n",
    "\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ./data/processed_014_raw.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64)  idle\n",
      "    Range : 0 ... 263551 =      0.000 ...  2058.992 secs\n",
      "Ready.\n",
      "Reading 0 ... 263551  =      0.000 ...  2058.992 secs...\n"
     ]
    }
   ],
   "source": [
    "# reduce bids eeg data\n",
    "if not os.path.isfile(f\"./data/processed_{SUBJECT}_raw.fif\"):\n",
    "    blocks = split_in_blocks(raw.copy())\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_channels.json\"):\n",
    "        bads = json.load(open(\"./data/bad_channels.json\"))\n",
    "    else:\n",
    "        bads = create_bad_json_structure()\n",
    "\n",
    "    for b in blocks:\n",
    "        b.plot()\n",
    "        plt.show(block=True)\n",
    "        bads[int(SUBJECT)][blocks.index(b)] = b.info['bads']\n",
    "\n",
    "    interpol_raw = interpolate_bads_and_merge(blocks)\n",
    "    prep_raw = preprocessing(interpol_raw.copy())\n",
    "    save_preprocessed_data(f\"./data/processed_{SUBJECT}_raw.fif\", prep_raw)\n",
    "\n",
    "else:\n",
    "    prep_raw = mne.io.read_raw_fif(f\"./data/processed_{SUBJECT}_raw.fif\", preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = prep_raw[0,:]\n",
    "#print(series[0][0])\n",
    "plt.plot(series[0][0])\n",
    "plt.show()\n",
    "plt.plot(series[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Annotations | 3969 segments: BAD boundary (6), EDGE boundary (6), ...>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with some electrodes\n",
    "\n",
    "raw_subselect = prep_raw.copy().pick([\"Cz\", \"T7\", \"T8\", \"P3\", \"P4\"])\n",
    "raw_subselect.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_deviantE', 'STATUS:five6_deviantEcorrect_E', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "{'STATUS:five6_deviantE': 7, 'STATUS:five6_deviantEcorrect_E': 8, 'STATUS:five6_deviantF': 9, 'STATUS:five6_deviantFcorrect_F': 10, 'STATUS:fiveRoot_deviantE': 12, 'STATUS:fiveRoot_deviantEcorrect_E': 13, 'STATUS:fiveRoot_deviantF': 14, 'STATUS:fiveRoot_deviantFcorrect_F': 15, 'STATUS:four6_deviantE': 18, 'STATUS:four6_deviantEcorrect_E': 19, 'STATUS:four6_deviantF': 20, 'STATUS:four6_deviantFcorrect_F': 21, 'STATUS:fourRoot_deviantE': 24, 'STATUS:fourRoot_deviantEcorrect_E': 25, 'STATUS:fourRoot_deviantF': 26, 'STATUS:fourRoot_deviantFcorrect_F': 27}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Copied from exercise 1, has to be adapted. Change selection of electrodes to electrodes near the ears? --> Cz is apparently connected to N2c\n",
    "evts,evts_dict = mne.events_from_annotations(raw_subselect)\n",
    "\n",
    "# not sure what annotations to use here\n",
    "# wanted_keys = [e for e in evts_dict.keys() if 'STATUS:two' in e]\n",
    "\n",
    "# deviant events (get all deviant events)\n",
    "deviant_keys = [e for e in evts_dict.keys() if 'deviant' in e]\n",
    "\n",
    "evts_dict_stim=dict((k, evts_dict[k]) for k in deviant_keys if k in evts_dict)\n",
    "\n",
    "print(evts_dict_stim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "193 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 193 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_deviantE', 'STATUS:five6_deviantEcorrect_E', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mauff\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mne\\viz\\ica.py:167: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize, facecolor=[0.95] * 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "List of components: [0, 1, 3]\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (5 components)\n",
      "    Zeroing out 3 ICA components\n",
      "    Projecting back using 5 PCA components\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 400 ms before stimulus onset, 1600 ms after stimulus onset - Stimulus 2 --> since each chord lasts 400ms --> 0s - 2000\n",
    "# maybe add baseline=(0.3,0.4) according to paper --> then no ica though? -> why?\n",
    "raw_subselect.info.normalize_proj()\n",
    "\n",
    "# EITHER use total threshold -250uV - 250uV \n",
    "reject = dict(eeg=0.0005) # in V\n",
    "epochs = mne.Epochs(raw_subselect, evts, evts_dict_stim, tmin=-0.4, tmax=1.6, baseline=(0,0.4), preload=True, reject=reject)\n",
    "\n",
    "# OR use annotations\n",
    "\"\"\" annotations, bads = prep.annotate_amplitude(raw_subselect, flat=dict(eeg=-250 * 1e-6), peak=dict(eeg=250 * 1e-6), picks=\"eeg\")\n",
    "raw_subselect.set_annotations(annotations)\n",
    "epochs = mne.Epochs(raw_subselect, evts, evts_dict_stim, tmin=-0.4, tmax=1.6, baseline=(0.3,0.4), preload=True, reject_by_annotation=True) \"\"\"\n",
    "\n",
    "\n",
    "# remove deviant epochs with reaction time under 200ms\n",
    "correct_keys = [e for e in evts_dict.keys() if 'correct' in e]\n",
    "correct_evt_ids = [evts_dict[key] for key in correct_keys]\n",
    "\n",
    "# get all event times\n",
    "event_times = epochs.events[:, 0] / epochs.info['sfreq']\n",
    "\n",
    "# if a correct event exists less than 600ms in the epoch (epochs starts 400ms before deviant + 200ms reactiontime), remove deviant event\n",
    "epochs_to_remove = []\n",
    "for i in range(len(event_times) - 1):\n",
    "    current_time = event_times[i]\n",
    "    next_time = event_times[i + 1]\n",
    "\n",
    "    # Check if the next event is a correct one and within 600ms\n",
    "    if (epochs.events[i + 1, 2] in correct_evt_ids and \n",
    "        (next_time - current_time) < 0.6):\n",
    "        epochs_to_remove.append(i)\n",
    "\n",
    "\n",
    "# Remove the epochs with unrealistic (<200ms) reaction time\n",
    "epochs_to_keep = [i for i in range(len(epochs)) if i not in epochs_to_remove]\n",
    "epochs = epochs[epochs_to_keep]\n",
    "\n",
    "# TODO: ICA vor oder nach Epoching?\n",
    "ica = get_ica(raw_subselect)\n",
    "#ica = get_ica(epochs)\n",
    "\n",
    "# extract data from epochs object\n",
    "data = epochs.get_data()\n",
    "times = epochs.times\n",
    "\n",
    "n_trials = 3 # use data.shape[0] for all\n",
    "fig, axs = plt.subplots(n_trials, 1, figsize=(10, 3*n_trials), sharex=True, sharey=True)\n",
    "\n",
    "# plot selected trials\n",
    "for i in range(n_trials):\n",
    "    for ch in range(data.shape[1]):\n",
    "        axs[i].plot(times, data[i, ch, :], label=f'Channel {ch}')\n",
    "    axs[i].set_title(f'Trial {i}')\n",
    "    axs[i].legend(loc='upper right')\n",
    "\n",
    "# label the x-axis\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len after:  24024915\n"
     ]
    }
   ],
   "source": [
    "epochs_concat = np.array(epochs)\n",
    "concat = []\n",
    "epochs_concat_removed = []\n",
    "removed = 0\n",
    "\n",
    "for index, epoch in enumerate(epochs_concat[:]):\n",
    "    for channel in epoch:\n",
    "        concat = np.concatenate((concat, channel))\n",
    "    mean_concat = np.mean(concat)\n",
    "    std_concat = np.std(concat)\n",
    "    for signal in concat:\n",
    "        if(signal > mean_concat - (5 * std_concat) and signal < mean_concat + (5 * std_concat) or signal < (-250 * 1e-6) or signal > (250 * 1e-6)):\n",
    "            epochs_concat_removed.append(signal)\n",
    "\n",
    "print(\"len after: \", len(epochs_concat_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len prior:  193\n",
      "remove  -5.9523672294814104e-05\n",
      "remove  -5.781054439996942e-05\n",
      "len after:  191\n"
     ]
    }
   ],
   "source": [
    "epochs_channel = np.array(epochs)\n",
    "print(\"len prior: \", len(epochs_channel))\n",
    "\n",
    "for index, epoch in enumerate(epochs_channel):\n",
    "    for channel in epoch:\n",
    "        mean_channel = np.mean(channel)\n",
    "        std_channel = np.std(channel)\n",
    "        for signal in channel:\n",
    "            if(signal < mean_channel - (5 * std_channel) or signal > mean_channel + (5 * std_channel) or signal < (-250 * 1e-6) or signal > (250 * 1e-6)):\n",
    "                print(\"remove \", signal)\n",
    "                epochs_channel = np.delete(epochs_channel, index, 0)\n",
    "\n",
    "print(\"len after: \", len(epochs_channel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
