{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing and Filtering of Chord-Oddball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "import ccs_eeg_utils\n",
    "import numpy as np\n",
    "import mne.preprocessing as prep\n",
    "import os\n",
    "import sklearn \n",
    "from contextlib import contextmanager\n",
    "from autoreject import AutoReject\n",
    "import json\n",
    "\n",
    "from mne_bids import (BIDSPath, read_raw_bids, write_raw_bids, inspect_dataset)\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# path where dataset is stored\n",
    "bids_root = \"./data/ds003570/\"\n",
    "TASK = 'AuditoryOddballChords'\n",
    "SUBJECT = '014'\n",
    "SUPRESS_BIDS_OUTPUT = True\n",
    "PROMPT_BADS = False\n",
    "USE_ICA_JSON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager to suppress stdout and stderr\n",
    "@contextmanager\n",
    "def suppress_stdout_stderr():\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "def read_raw_data(subject_id):\n",
    "    bids_path = BIDSPath(subject=subject_id,\n",
    "                         datatype='eeg', suffix='eeg', task=TASK,\n",
    "                         root=bids_root)\n",
    "\n",
    "    if SUPRESS_BIDS_OUTPUT:\n",
    "        with suppress_stdout_stderr():\n",
    "            raw = read_raw_bids(bids_path)\n",
    "    else:\n",
    "        raw = read_raw_bids(bids_path)\n",
    "\n",
    "    # Inplace?\n",
    "    ccs_eeg_utils.read_annotations_core(bids_path, raw)\n",
    "    raw.load_data()\n",
    "    \n",
    "    return raw, bids_path\n",
    "\n",
    "def preprocessing(raw):\n",
    "    # TODO: bandpass first, downsample later? -> expensive!\n",
    "    # 1. Downsampling to 128 Hz\n",
    "    if raw.info['sfreq'] > 128:\n",
    "        raw.resample(128)\n",
    "\n",
    "    # Set channel types to EEG if not already set\n",
    "    if not all(ch_type in ['eeg', 'stim'] for ch_type in raw.get_channel_types()):\n",
    "        eeg_channel_names = raw.ch_names\n",
    "        channel_types = {name: 'eeg' for name in eeg_channel_names}\n",
    "        raw.set_channel_types(channel_types)\n",
    "\n",
    "    # 2. Band-pass filter between 0.5 Hz and 30 Hz\n",
    "    raw.filter(0.5, 30, fir_design='firwin')\n",
    "\n",
    "    # 3. Re-referencing to the average activity of all electrodes\n",
    "    #TODO: add apply_proj() here to apply arp?\n",
    "    raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "    \"\"\" events = prep.find_eog_events(raw)\n",
    "    print(events) \"\"\"\n",
    "\n",
    "    # 5. Data Reduction (optional)\n",
    "    # For instance, crop the first 60 seconds of the data\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def save_preprocessed_data(file_path, raw):\n",
    "    \"\"\"\n",
    "    Saves the preprocessed EEG data to a file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path where the preprocessed data will be saved.\n",
    "    raw (mne.io.Raw): The preprocessed MNE Raw object containing EEG data.\n",
    "    \"\"\"\n",
    "    # Check if file_path ends with .fif extension\n",
    "    if not file_path.endswith('.fif'):\n",
    "        file_path += '.fif'\n",
    "\n",
    "    # Save the data\n",
    "    try:\n",
    "        raw.save(file_path, overwrite=True)\n",
    "        print(f\"Data saved successfully to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data: {e}\")\n",
    "\n",
    "# see https://neuraldatascience.io/7-eeg/erp_artifacts.html\n",
    "def get_ica(data, ica_bads, block_idx):\n",
    "    data.set_montage('standard_1020', match_case=False)\n",
    "    ica = mne.preprocessing.ICA(method=\"fastica\", random_state=0)\n",
    "  \n",
    "    ica.fit(data, verbose=True)\n",
    "\n",
    "    if USE_ICA_JSON:\n",
    "        exclude_components = ica_bads[f\"sub-{SUBJECT}\"][block_idx]\n",
    "    else:\n",
    "        ica.plot_components()\n",
    "        #ica.plot_properties(data)\n",
    "        # components to be excluded\n",
    "        # add python input to determine which components to exclude\n",
    "        input_str = input(\"Enter index of the components to be separated by space: \")  \n",
    "        # Converting input string to a list of integers  \n",
    "        exclude_components = input_str.split()  \n",
    "        exclude_components = [int(num) for num in exclude_components]  \n",
    "        \n",
    "        ica_bads[f\"sub-{SUBJECT}\"][block_idx] = exclude_components\n",
    "\n",
    "    # Printing the list  \n",
    "    print(\"List of components:\", exclude_components) \n",
    "    ica.exclude = exclude_components\n",
    "    reconst_raw = data.copy()\n",
    "    # apply with excluded components\n",
    "    reconst_raw = ica.apply(reconst_raw)\n",
    "    \n",
    "    return reconst_raw\n",
    "\n",
    "\n",
    "def split_in_blocks(raw):\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Identify indices of 'STATUS:boundary' events\n",
    "    boundary_events = events[events[:, 2] == event_id['STATUS:boundary'], 0]\n",
    "\n",
    "    # Split the data into blocks\n",
    "    blocks = []\n",
    "    start_idx = 0\n",
    "    for end_idx in boundary_events:\n",
    "        block = raw.copy().crop(tmin=raw.times[start_idx], tmax=raw.times[end_idx])\n",
    "        blocks.append(block)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    block = raw.copy().crop(tmin=raw.times[start_idx])\n",
    "    blocks.append(block)    \n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def get_epochs_from_events(data, event_str, reaction_time_threshold=None):\n",
    "    evts,evts_dict = mne.events_from_annotations(data)\n",
    "\n",
    "    # not sure what annotations to use here\n",
    "    # wanted_keys = [e for e in evts_dict.keys() if 'STATUS:two' in e]\n",
    "\n",
    "    # deviant events (get all deviant events)\n",
    "    deviant_keys = [e for e in evts_dict.keys() if event_str in e]\n",
    "\n",
    "    evts_dict_stim=dict((k, evts_dict[k]) for k in deviant_keys if k in evts_dict)\n",
    "\n",
    "    data.info.normalize_proj()\n",
    "\n",
    "    # EITHER use total threshold -250uV - 250uV \n",
    "    reject = dict(eeg=0.0004) # in V\n",
    "    epochs = mne.Epochs(data, evts, evts_dict_stim, tmin=-0.4, tmax=1.6, baseline=(-0.4,0), preload=True, reject=reject)\n",
    "\n",
    "\n",
    "    if reaction_time_threshold:\n",
    "        correct_keys = [e for e in evts_dict.keys() if 'Correct -' in e]\n",
    "        correct_evt_ids = [evts_dict[key] for key in correct_keys]\n",
    "\n",
    "        # get all event times\n",
    "        event_times = epochs.events[:, 0] / epochs.info['sfreq']\n",
    "\n",
    "        # if a correct event exists less than 600ms in the epoch (epochs starts 400ms before deviant + 200ms reactiontime), remove deviant event\n",
    "        epochs_to_remove = []\n",
    "        for i in range(len(event_times) - 1):\n",
    "            current_time = event_times[i]\n",
    "            next_time = event_times[i + 1]\n",
    "\n",
    "            # Check if the next event is a correct one and within 600ms\n",
    "            if (epochs.events[i + 1, 2] in correct_evt_ids and \n",
    "                (next_time - current_time) < 0.6):\n",
    "                epochs_to_remove.append(i)\n",
    "\n",
    "        # Remove the epochs with unrealistic (<200ms) reaction time\n",
    "        epochs_to_keep = [i for i in range(len(epochs)) if i not in epochs_to_remove]\n",
    "        epochs = epochs[epochs_to_keep]\n",
    "\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def interpolate_bads_and_merge(blocks):\n",
    "    # Interpolate bad channels\n",
    "    for block in blocks:\n",
    "        block.interpolate_bads()\n",
    "\n",
    "    # Merge the blocks\n",
    "    raw = mne.concatenate_raws(blocks)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def create_bad_json_structure():\n",
    "    subjects = {}\n",
    "    for s in range(1, 41):\n",
    "        subject_key = f'sub-{s:03d}'\n",
    "        subjects[subject_key] = {}\n",
    "        for b in range(1, 9):\n",
    "            block_key = f'{b}'\n",
    "            subjects[subject_key][block_key] = []\n",
    "\n",
    "    return subjects\n",
    "\n",
    "def set_bad_channels_from_json(blocks, bad_json):\n",
    "    for block in blocks:\n",
    "        # Set bad channels\n",
    "        block.info['bads'] = bad_json[f\"sub-{SUBJECT}\"][f\"{blocks.index(block)+1}\"]\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce bids eeg data\n",
    "if not os.path.isfile(f\"./data/processed_{SUBJECT}_raw.fif\"):\n",
    "    raw, bids_path = read_raw_data(SUBJECT)\n",
    "    channel_types = {ch: 'eeg' for ch in raw.ch_names}\n",
    "    raw.set_channel_types(channel_types)\n",
    "\n",
    "    raw.set_montage('standard_1020', match_case=False)\n",
    "    blocks = split_in_blocks(raw.copy())\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_channels.json\"):\n",
    "        bads = json.load(open(\"./data/bad_channels.json\"))\n",
    "        blocks = set_bad_channels_from_json(blocks, bads)\n",
    "    else:\n",
    "        bads = create_bad_json_structure()\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_ica_components.json\"):\n",
    "        ica_bads = json.load(open(\"./data/bad_ica_components.json\"))\n",
    "        blocks = set_bad_channels_from_json(blocks, bads)\n",
    "    else:\n",
    "        ica_bads = create_bad_json_structure()\n",
    "\n",
    "    if PROMPT_BADS == True:\n",
    "        for b in blocks:\n",
    "            b.plot(n_channels=64)\n",
    "            plt.show(block=True)\n",
    "            bads[f\"sub-{SUBJECT}\"][f\"{blocks.index(b)+1}\"] = b.info['bads']\n",
    "    \n",
    "    with open(\"./data/bad_channels.json\", \"w\") as f:\n",
    "        json.dump(bads, f)\n",
    "\n",
    "    ica_blocks = []\n",
    "\n",
    "    for b in blocks:\n",
    "        b.interpolate_bads()\n",
    "        prep_block = preprocessing(b.copy())\n",
    "\n",
    "        # ICA\n",
    "        ica_block = get_ica(prep_block, ica_bads, f\"{blocks.index(b)+1}\")\n",
    "        ica_blocks.append(ica_block)\n",
    "    \n",
    "    with open(\"./data/bad_ica_components.json\", \"w\") as f:\n",
    "        json.dump(ica_bads, f)\n",
    "\n",
    "    prep_raw = mne.concatenate_raws(ica_blocks)\n",
    "    save_preprocessed_data(f\"./data/processed_{SUBJECT}_raw.fif\", prep_raw)\n",
    "\n",
    "else:\n",
    "    prep_raw = mne.io.read_raw_fif(f\"./data/processed_{SUBJECT}_raw.fif\", preload=True)\n",
    "\n",
    "prep_raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = prep_raw[0,:]\n",
    "#print(series[0][0])\n",
    "plt.plot(series[0][0])\n",
    "plt.show()\n",
    "plt.plot(series[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with some electrodes\n",
    "\n",
    "raw_subselect = prep_raw.copy()#.pick([\"Cz\", \"T7\", \"T8\", \"P3\", \"P4\"])\n",
    "raw_subselect.annotations\n",
    "\n",
    "standard_epochs = get_epochs_from_events(raw_subselect, '_S')\n",
    "exemplar_epochs = get_epochs_from_events(raw_subselect, '_deviantEcorrect_E', reaction_time_threshold=0.2)\n",
    "function_epochs = get_epochs_from_events(raw_subselect, '_deviantFcorrect_F', reaction_time_threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_rejection(epochs, shape):\n",
    "    epochs_concat = epochs.copy()\n",
    "    concat = []\n",
    "    epochs_concat_removed = np.zeros(shape=shape)\n",
    "    print(\"len prior: \", len(epochs_concat))\n",
    "\n",
    "    for epoch in epochs_concat:\n",
    "        for channel in epoch:\n",
    "            concat = np.concatenate((concat, channel))\n",
    "        std_concat = np.std(concat)\n",
    "        for channel in epoch:\n",
    "            channel_max = np.max(abs(channel))\n",
    "            std_channel = np.std(channel)\n",
    "\n",
    "            if(channel_max < (5 * std_concat)  and channel_max < (250 * 1e-6)  and channel_max < (5 * std_channel)):\n",
    "                np.append(epochs_concat_removed, channel)\n",
    "\n",
    "    print(\"len after: \", len(epochs_concat_removed))\n",
    "\n",
    "    return epochs_concat_removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_epochs = epoch_rejection(exemplar_epochs.get_data(), np.array(exemplar_epochs.get_data()).shape )\n",
    "# exemplar_epochs = epoch_rejection_prob(exemplar_epochs.get_data())\n",
    "\n",
    "function_epochs = epoch_rejection(function_epochs.get_data(), np.array(function_epochs.get_data()).shape)\n",
    "# function_epochs = epoch_rejection_prob(function_epochs.get_data())\n",
    "\n",
    "standard_epochs = epoch_rejection(standard_epochs.get_data(), np.array(standard_epochs.get_data()).shape)\n",
    "# standard_epochs = epoch_rejection_prob(standard_epochs.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.analysis import generate_AUC_ROC\n",
    "step = 1\n",
    "\n",
    "roc_exemplar = generate_AUC_ROC(standard_epochs, exemplar_epochs, 7, step)\n",
    "#print(roc_exemplar)\n",
    "roc_function = generate_AUC_ROC(standard_epochs, function_epochs, 7, step)\n",
    "#print(roc_function)\n",
    "time = [i*step/128 -0.4 for i in range(len(roc_exemplar))]\n",
    "\n",
    "plt.plot(time, roc_exemplar, label=\"exemplar\")\n",
    "plt.plot(time, roc_function, label=\"function\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(exemplar_epochs.get_data()).shape)\n",
    "print(np.array(function_epochs.get_data()).shape)\n",
    "print(np.array(standard_epochs.get_data()).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
