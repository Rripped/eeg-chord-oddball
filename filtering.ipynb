{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing and Filtering of Chord-Oddball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "import ccs_eeg_utils\n",
    "import numpy as np\n",
    "import mne.preprocessing as prep\n",
    "import os\n",
    "import sklearn \n",
    "from contextlib import contextmanager\n",
    "from autoreject import AutoReject\n",
    "import json\n",
    "\n",
    "from mne_bids import (BIDSPath, read_raw_bids, write_raw_bids, inspect_dataset)\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# path where dataset is stored\n",
    "bids_root = \"./data/ds003570/\"\n",
    "TASK = 'AuditoryOddballChords'\n",
    "SUBJECT = '014'\n",
    "SUPRESS_BIDS_OUTPUT = True\n",
    "PROMPT_BADS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager to suppress stdout and stderr\n",
    "@contextmanager\n",
    "def suppress_stdout_stderr():\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "def read_raw_data(subject_id):\n",
    "    bids_path = BIDSPath(subject=subject_id,\n",
    "                         datatype='eeg', suffix='eeg', task=TASK,\n",
    "                         root=bids_root)\n",
    "\n",
    "    if SUPRESS_BIDS_OUTPUT:\n",
    "        with suppress_stdout_stderr():\n",
    "            raw = read_raw_bids(bids_path)\n",
    "    else:\n",
    "        raw = read_raw_bids(bids_path)\n",
    "\n",
    "    # Inplace?\n",
    "    ccs_eeg_utils.read_annotations_core(bids_path, raw)\n",
    "    raw.load_data()\n",
    "    \n",
    "    return raw, bids_path\n",
    "\n",
    "def preprocessing(raw):\n",
    "    # TODO: bandpass first, downsample later? -> expensive!\n",
    "    # 1. Downsampling to 128 Hz\n",
    "    if raw.info['sfreq'] > 128:\n",
    "        raw.resample(128)\n",
    "\n",
    "    # Set channel types to EEG if not already set\n",
    "    if not all(ch_type in ['eeg', 'stim'] for ch_type in raw.get_channel_types()):\n",
    "        eeg_channel_names = raw.ch_names\n",
    "        channel_types = {name: 'eeg' for name in eeg_channel_names}\n",
    "        raw.set_channel_types(channel_types)\n",
    "\n",
    "    # 2. Band-pass filter between 0.5 Hz and 30 Hz\n",
    "    raw.filter(0.5, 30, fir_design='firwin')\n",
    "\n",
    "    # 3. Re-referencing to the average activity of all electrodes\n",
    "    #TODO: add apply_proj() here to apply arp?\n",
    "    raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "    \"\"\" events = prep.find_eog_events(raw)\n",
    "    print(events) \"\"\"\n",
    "\n",
    "    # 5. Data Reduction (optional)\n",
    "    # For instance, crop the first 60 seconds of the data\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def save_preprocessed_data(file_path, raw):\n",
    "    \"\"\"\n",
    "    Saves the preprocessed EEG data to a file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path where the preprocessed data will be saved.\n",
    "    raw (mne.io.Raw): The preprocessed MNE Raw object containing EEG data.\n",
    "    \"\"\"\n",
    "    # Check if file_path ends with .fif extension\n",
    "    if not file_path.endswith('.fif'):\n",
    "        file_path += '.fif'\n",
    "\n",
    "    # Save the data\n",
    "    try:\n",
    "        raw.save(file_path, overwrite=True)\n",
    "        print(f\"Data saved successfully to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data: {e}\")\n",
    "\n",
    "# see https://neuraldatascience.io/7-eeg/erp_artifacts.html\n",
    "def get_ica(data):\n",
    "    data.set_montage('standard_1020', match_case=False)\n",
    "    ica = mne.preprocessing.ICA(method=\"fastica\")\n",
    "    blocks = split_in_blocks(data.copy())\n",
    "    for block in blocks:\n",
    "        ica.fit(block, verbose=True)\n",
    "        #ica.plot_components()\n",
    "        ica.plot_properties(block)\n",
    "    # components to be excluded\n",
    "    # add python input to determine which components to exclude\n",
    "    input_str = input(\"Enter index of the components to be separated by space: \")  \n",
    "    # Converting input string to a list of integers  \n",
    "    exclude_components = input_str.split()  \n",
    "    exclude_components = [int(num) for num in exclude_components]  \n",
    "  \n",
    "    # Printing the list  \n",
    "    print(\"List of components:\", exclude_components) \n",
    "    ica.exclude = exclude_components\n",
    "    reconst_raw = data.copy()\n",
    "    # apply with excluded components\n",
    "    ica.apply(reconst_raw)\n",
    "    \n",
    "    # TODO: add finf_bads_ of mne.ICA?\n",
    "    return ica\n",
    "\n",
    "\n",
    "def split_in_blocks(raw):\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Identify indices of 'STATUS:boundary' events\n",
    "    boundary_events = events[events[:, 2] == event_id['STATUS:boundary'], 0]\n",
    "\n",
    "    # Split the data into blocks\n",
    "    blocks = []\n",
    "    start_idx = 0\n",
    "    for end_idx in boundary_events:\n",
    "        block = raw.copy().crop(tmin=raw.times[start_idx], tmax=raw.times[end_idx])\n",
    "        blocks.append(block)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def get_epochs_from_events(data, event_str, reaction_time_threshold=None):\n",
    "    evts,evts_dict = mne.events_from_annotations(data)\n",
    "\n",
    "    # not sure what annotations to use here\n",
    "    # wanted_keys = [e for e in evts_dict.keys() if 'STATUS:two' in e]\n",
    "\n",
    "    # deviant events (get all deviant events)\n",
    "    deviant_keys = [e for e in evts_dict.keys() if event_str in e]\n",
    "\n",
    "    evts_dict_stim=dict((k, evts_dict[k]) for k in deviant_keys if k in evts_dict)\n",
    "\n",
    "    data.info.normalize_proj()\n",
    "\n",
    "    # EITHER use total threshold -250uV - 250uV \n",
    "    reject = dict(eeg=0.0005) # in V\n",
    "    epochs = mne.Epochs(data, evts, evts_dict_stim, tmin=-0.4, tmax=1.6, baseline=(0,0.4), preload=True, reject=reject)\n",
    "\n",
    "\n",
    "    if reaction_time_threshold:\n",
    "        correct_keys = [e for e in evts_dict.keys() if 'Correct -' in e]\n",
    "        correct_evt_ids = [evts_dict[key] for key in correct_keys]\n",
    "\n",
    "        # get all event times\n",
    "        event_times = epochs.events[:, 0] / epochs.info['sfreq']\n",
    "\n",
    "        # if a correct event exists less than 600ms in the epoch (epochs starts 400ms before deviant + 200ms reactiontime), remove deviant event\n",
    "        epochs_to_remove = []\n",
    "        for i in range(len(event_times) - 1):\n",
    "            current_time = event_times[i]\n",
    "            next_time = event_times[i + 1]\n",
    "\n",
    "            # Check if the next event is a correct one and within 600ms\n",
    "            if (epochs.events[i + 1, 2] in correct_evt_ids and \n",
    "                (next_time - current_time) < 0.6):\n",
    "                epochs_to_remove.append(i)\n",
    "\n",
    "        # Remove the epochs with unrealistic (<200ms) reaction time\n",
    "        epochs_to_keep = [i for i in range(len(epochs)) if i not in epochs_to_remove]\n",
    "        epochs = epochs[epochs_to_keep]\n",
    "\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def interpolate_bads_and_merge(blocks):\n",
    "    # Interpolate bad channels\n",
    "    for block in blocks:\n",
    "        block.interpolate_bads()\n",
    "\n",
    "    # Merge the blocks\n",
    "    raw = mne.concatenate_raws(blocks)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def create_bad_json_structure():\n",
    "    subjects = {}\n",
    "    for s in range(1, 41):\n",
    "        subject_key = f'sub-{s:03d}'\n",
    "        subjects[subject_key] = {}\n",
    "        for b in range(1, 9):\n",
    "            block_key = f'{b}'\n",
    "            subjects[subject_key][block_key] = []\n",
    "\n",
    "    return subjects\n",
    "\n",
    "def set_bad_channels_from_json(blocks, bad_json):\n",
    "    for block in blocks:\n",
    "        # Set bad channels\n",
    "        block.info['bads'] = bad_json[f\"sub-{SUBJECT}\"][f\"{blocks.index(block)+1}\"]\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce bids eeg data\n",
    "if not os.path.isfile(f\"./data/processed_{SUBJECT}_raw.fif\"):\n",
    "    raw, bids_path = read_raw_data(SUBJECT)\n",
    "    channel_types = {ch: 'eeg' for ch in raw.ch_names}\n",
    "    raw.set_channel_types(channel_types)\n",
    "\n",
    "    raw.set_montage('standard_1020', match_case=False)\n",
    "    blocks = split_in_blocks(raw.copy())\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_channels.json\"):\n",
    "        bads = json.load(open(\"./data/bad_channels.json\"))\n",
    "        blocks = set_bad_channels_from_json(blocks, bads)\n",
    "    else:\n",
    "        bads = create_bad_json_structure()\n",
    "\n",
    "    if PROMPT_BADS == True:\n",
    "        for b in blocks:\n",
    "            b.plot(n_channels=64)\n",
    "            plt.show(block=True)\n",
    "            bads[f\"sub-{SUBJECT}\"][f\"{blocks.index(b)+1}\"] = b.info['bads']\n",
    "    \n",
    "    with open(\"./data/bad_channels.json\", \"w\") as f:\n",
    "        json.dump(bads, f)\n",
    "\n",
    "    interpol_raw = interpolate_bads_and_merge(blocks)\n",
    "    prep_raw = preprocessing(interpol_raw.copy())\n",
    "    save_preprocessed_data(f\"./data/processed_{SUBJECT}_raw.fif\", prep_raw)\n",
    "\n",
    "else:\n",
    "    prep_raw = mne.io.read_raw_fif(f\"./data/processed_{SUBJECT}_raw.fif\", preload=True)\n",
    "\n",
    "prep_raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = prep_raw[0,:]\n",
    "#print(series[0][0])\n",
    "plt.plot(series[0][0])\n",
    "plt.show()\n",
    "plt.plot(series[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_deviantE', 'STATUS:five6_deviantEcorrect_E', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "Not setting metadata\n",
      "1067 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 1067 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_deviantE', 'STATUS:five6_deviantEcorrect_E', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_deviantE', 'STATUS:five6_deviantEcorrect_E', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 90 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# test with some electrodes\n",
    "\n",
    "raw_subselect = prep_raw.copy().pick([\"Cz\", \"T7\", \"T8\", \"P3\", \"P4\"])\n",
    "raw_subselect.annotations\n",
    "\n",
    "standard_epochs = get_epochs_from_events(raw_subselect, '_S')\n",
    "exemplar_epochs = get_epochs_from_events(raw_subselect, '_deviantEcorrect_E', reaction_time_threshold=0.2)\n",
    "function_epochs = get_epochs_from_events(raw_subselect, '_deviantFcorrect_F', reaction_time_threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_deviantE', 'STATUS:five6_deviantEcorrect_E', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.0s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.4s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "149 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.1s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.0s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linus/git/uni/eeg-chord-oddball/venv/lib/python3.11/site-packages/mne/viz/ica.py:167: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize, facecolor=[0.95] * 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "145 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Fitting ICA to data using 5 channels (please be patient, this may take a while)\n",
      "Selecting by non-zero PCA components: 5 components\n",
      "Fitting ICA took 0.0s.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "146 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "List of components: []\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (5 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 5 PCA components\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: ICA vor oder nach Epoching?\n",
    "ica = get_ica(raw_subselect)\n",
    "#ica = get_ica(epochs)\n",
    "\n",
    "# extract data from exemplar epochs object\n",
    "# e_data = exemplar_epochs.get_data()\n",
    "# e_times = exemplar_epochs.times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_rejection_value(epochs):\n",
    "    epochs_concat = np.array(epochs)\n",
    "    concat = []\n",
    "    epochs_concat_removed = []\n",
    "\n",
    "    for _, epoch in enumerate(epochs_concat[:]):\n",
    "        for channel in epoch:\n",
    "            concat = np.concatenate((concat, channel))\n",
    "        mean_concat = np.mean(concat)\n",
    "        std_concat = np.std(concat)\n",
    "        for signal in concat:\n",
    "            if(signal > mean_concat - (5 * std_concat) and signal < mean_concat + (5 * std_concat) or signal < (-250 * 1e-6) or signal > (250 * 1e-6)):\n",
    "                epochs_concat_removed.append(signal)\n",
    "\n",
    "    print(\"len after: \", len(epochs_concat_removed))\n",
    "\n",
    "    return epochs_concat_removed\n",
    "\n",
    "\n",
    "def epoch_rejection_prob(epochs):\n",
    "    epochs_channel = np.array(epochs)\n",
    "    print(\"len prior: \", len(epochs_channel))\n",
    "\n",
    "    for index, epoch in enumerate(epochs_channel):\n",
    "        for channel in epoch:\n",
    "            mean_channel = np.mean(channel)\n",
    "            std_channel = np.std(channel)\n",
    "            for signal in channel:\n",
    "                if(signal < mean_channel - (5 * std_channel) or signal > mean_channel + (5 * std_channel) or signal < (-250 * 1e-6) or signal > (250 * 1e-6)):\n",
    "                    print(\"remove \", signal)\n",
    "                    epochs_channel = np.delete(epochs_channel, index, 0)\n",
    "\n",
    "    print(\"len after: \", len(epochs_channel))\n",
    "\n",
    "    return epochs_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exemplar_epochs \u001b[38;5;241m=\u001b[39m epoch_rejection_value(\u001b[43mexemplar_epochs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# exemplar_epochs = epoch_rejection_prob(exemplar_epochs.get_data())\u001b[39;00m\n\u001b[1;32m      4\u001b[0m function_epochs \u001b[38;5;241m=\u001b[39m epoch_rejection_value(function_epochs\u001b[38;5;241m.\u001b[39mget_data())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_data'"
     ]
    }
   ],
   "source": [
    "exemplar_epochs = epoch_rejection_value(exemplar_epochs.get_data())\n",
    "# exemplar_epochs = epoch_rejection_prob(exemplar_epochs.get_data())\n",
    "\n",
    "function_epochs = epoch_rejection_value(function_epochs.get_data())\n",
    "# function_epochs = epoch_rejection_prob(function_epochs.get_data())\n",
    "\n",
    "standard_epochs = epoch_rejection_value(standard_epochs.get_data())\n",
    "# standard_epochs = epoch_rejection_prob(standard_epochs.get_data())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
