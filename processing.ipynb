{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of Chord-Oddball data\n",
    "\n",
    "This notebook is used for obtaining the cleaned data and processes the raw data of the chord-oddball dataset to initiate the analysis. Guide for artifact removal (https://neuraldatascience.io/7-eeg/erp_artifacts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      SUBJECT: 038\n",
      "      BIDS_ROOT: ./data/ds003570/\n",
      "      TASK: AuditoryOddballChords\n",
      "      SUBJECT: 038\n",
      "      SUPRESS_BIDS_OUTPUT: True\n",
      "      PROMPT_BADS: False\n",
      "      USE_ICA_JSON: False\n",
      "      ICA_MANUAL: False\n",
      "      Z_SCORE_REJECT: False\n",
      "      PYPREP_REJECT: True\n",
      "      AUTOREJECT: False\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from autoreject import AutoReject\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import auc\n",
    "\n",
    "from pyprep.find_noisy_channels import NoisyChannels\n",
    "\n",
    "import custom.misc as misc\n",
    "import custom.preprocessing as prep\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SUBJECT = os.getenv(\"SUBJECT\")\n",
    "BIDS_ROOT = os.getenv(\"BIDS_ROOT\")\n",
    "TASK = os.getenv(\"TASK\")\n",
    "SUBJECT = os.getenv(\"SUBJECT\")\n",
    "SUPRESS_BIDS_OUTPUT = (os.getenv('SUPRESS_BIDS_OUTPUT', 'False') == 'True')\n",
    "PROMPT_BADS = (os.getenv('PROMPT_BADS', 'False') == 'True')\n",
    "USE_ICA_JSON = (os.getenv('USE_ICA_JSON', 'False') == 'True')\n",
    "ICA_MANUAL = (os.getenv('ICA_MANUAL', 'False') == 'True')\n",
    "Z_SCORE_REJECT = (os.getenv('Z_SCORE_REJECT', 'False') == 'True')\n",
    "PYPREP_REJECT = (os.getenv('PYPREP_REJECT', 'False') == 'True')\n",
    "AUTOREJECT = (os.getenv('AUTOREJECT', 'False') == 'True')\n",
    "\n",
    "print(f\"\"\"\n",
    "      SUBJECT: {SUBJECT}\n",
    "      BIDS_ROOT: {BIDS_ROOT}\n",
    "      TASK: {TASK}\n",
    "      SUBJECT: {SUBJECT}\n",
    "      SUPRESS_BIDS_OUTPUT: {SUPRESS_BIDS_OUTPUT}\n",
    "      PROMPT_BADS: {PROMPT_BADS}\n",
    "      USE_ICA_JSON: {USE_ICA_JSON}\n",
    "      ICA_MANUAL: {ICA_MANUAL}\n",
    "      Z_SCORE_REJECT: {Z_SCORE_REJECT}\n",
    "      PYPREP_REJECT: {PYPREP_REJECT}\n",
    "      AUTOREJECT: {AUTOREJECT}\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ./data/fifs/processed_038_raw.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64)  idle\n",
      "    Range : 0 ... 301439 =      0.000 ...  2354.992 secs\n",
      "Ready.\n",
      "Reading 0 ... 301439  =      0.000 ...  2354.992 secs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "            <td>sub-038</td>\n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>67 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>128.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>30.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Projections</th>\n",
       "        <td>Average EEG reference : off</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 13 non-empty values\n",
       " bads: []\n",
       " ch_names: Fp1, AF7, AF3, F1, F3, F5, F7, FT7, FC5, FC3, FC1, C1, C3, C5, ...\n",
       " chs: 64 EEG\n",
       " custom_ref_applied: False\n",
       " dig: 67 items (3 Cardinal, 64 EEG)\n",
       " file_id: 4 items (dict)\n",
       " highpass: 0.5 Hz\n",
       " line_freq: 60.0\n",
       " lowpass: 30.0 Hz\n",
       " meas_date: unspecified\n",
       " meas_id: 4 items (dict)\n",
       " nchan: 64\n",
       " projs: Average EEG reference: off\n",
       " sfreq: 128.0 Hz\n",
       " subject_info: 1 item (dict)\n",
       ">"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce bids eeg data\n",
    "if not os.path.isfile(f\"./data/fifs/processed_{SUBJECT}_raw.fif\"):\n",
    "    if SUPRESS_BIDS_OUTPUT:\n",
    "        with misc.suppress_stdout_stderr():\n",
    "            raw, bids_path = misc.read_raw_data(SUBJECT)\n",
    "    else:\n",
    "        raw, bids_path = misc.read_raw_data(SUBJECT)\n",
    "        \n",
    "    channel_types = {ch: 'eeg' for ch in raw.ch_names}\n",
    "    raw.set_channel_types(channel_types)\n",
    "    \n",
    "    elec_data = pd.read_csv('./data/ds003570/sub-'+SUBJECT+'/eeg/sub-'+SUBJECT+'_task-AuditoryOddballChords_electrodes.tsv', sep='\\t')\n",
    "    # ensure that the electrode names and positions are correctly used\n",
    "    montage = mne.channels.make_dig_montage(ch_pos=dict(zip(elec_data['name'], elec_data[['x', 'y', 'z']].values)),\n",
    "                                        coord_frame='head')\n",
    "    raw.set_montage(montage)\n",
    "    blocks = prep.split_in_blocks(raw.copy())\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_channels.json\"):\n",
    "        bads = json.load(open(\"./data/bad_channels.json\"))\n",
    "        blocks = prep.set_bad_channels_from_json(blocks, bads)\n",
    "    else:\n",
    "        bads = misc.create_bad_json_structure()\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_ica_components.json\"):\n",
    "        ica_bads = json.load(open(\"./data/bad_ica_components.json\"))\n",
    "    else:\n",
    "        ica_bads = misc.create_bad_json_structure()\n",
    "    \n",
    "    # deprecated, do not use\n",
    "    if Z_SCORE_REJECT == True:\n",
    "        for b in blocks:\n",
    "            # reject by z-score (autoreject is more sophisticated, but only works on epochs and is really slow)\n",
    "            b.info['bads'].extend(prep.mark_bad_channels_by_z_score(b, threshold=5.0, window_size=10000))\n",
    "            print(f\"Bad channels: {b.info['bads']}\")\n",
    "\n",
    "    if PYPREP_REJECT == True:\n",
    "        for b in blocks:\n",
    "            nc = NoisyChannels(b, random_state=42) # of course it has to be 42!\n",
    "            nc.find_all_bads(ransac=False)\n",
    "            b.info['bads'].extend(nc.get_bads())\n",
    "            print(f\"Bad channels: {b.info['bads']}\")\n",
    "\n",
    "    if PROMPT_BADS == True:\n",
    "        for b in blocks:\n",
    "            b.plot(n_channels=64)\n",
    "            plt.show(block=True)\n",
    "            bads[f\"sub-{SUBJECT}\"][f\"{blocks.index(b)+1}\"] = b.info['bads']\n",
    "    \n",
    "    \n",
    "    with open(\"./data/bad_channels.json\", \"w\") as f:\n",
    "        json.dump(bads, f)\n",
    "\n",
    "    ica_blocks = []\n",
    "\n",
    "    # separate preprocessing in 8 blocks as boundary events occured 8 times in the whole recording\n",
    "    for b in blocks:\n",
    "        b.interpolate_bads()\n",
    "        prep_block = prep.basic_preprocessing(b.copy())\n",
    "\n",
    "        # ICA\n",
    "        ica_block = prep.get_ica(prep_block, ica_bads, f\"{blocks.index(b)+1}\", montage)\n",
    "        ica_blocks.append(ica_block)\n",
    "    \n",
    "    with open(\"./data/bad_ica_components.json\", \"w\") as f:\n",
    "        json.dump(ica_bads, f)\n",
    "\n",
    "    prep_raw = mne.concatenate_raws(ica_blocks)\n",
    "    misc.save_preprocessed_data(f\"./data/fifs/processed_{SUBJECT}_raw.fif\", prep_raw)\n",
    "\n",
    "else:\n",
    "    prep_raw = mne.io.read_raw_fif(f\"./data/fifs/processed_{SUBJECT}_raw.fif\", preload=True)\n",
    "\n",
    "prep_raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_Sincorrect', 'STATUS:five6_deviantE', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_Sincorrect', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "Not setting metadata\n",
      "1111 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 1111 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_Sincorrect', 'STATUS:five6_deviantE', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_Sincorrect', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "Not setting metadata\n",
      "34 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 34 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtered 34 epochs out of 34 based on reaction time threshold\n",
      "Used Annotations descriptions: ['STATUS:16128', 'STATUS:Correct - Exemplar!', 'STATUS:Correct - Function!', 'STATUS:Incorrect - Standard!', 'STATUS:boundary', 'STATUS:five6_S', 'STATUS:five6_Sincorrect', 'STATUS:five6_deviantE', 'STATUS:five6_deviantF', 'STATUS:five6_deviantFcorrect_F', 'STATUS:fiveRoot_S', 'STATUS:fiveRoot_Sincorrect', 'STATUS:fiveRoot_deviantE', 'STATUS:fiveRoot_deviantEcorrect_E', 'STATUS:fiveRoot_deviantF', 'STATUS:fiveRoot_deviantFcorrect_F', 'STATUS:four6_S', 'STATUS:four6_Sincorrect', 'STATUS:four6_deviantE', 'STATUS:four6_deviantEcorrect_E', 'STATUS:four6_deviantF', 'STATUS:four6_deviantFcorrect_F', 'STATUS:fourRoot_S', 'STATUS:fourRoot_Sincorrect', 'STATUS:fourRoot_deviantE', 'STATUS:fourRoot_deviantEcorrect_E', 'STATUS:fourRoot_deviantF', 'STATUS:fourRoot_deviantFcorrect_F', 'STATUS:one', 'STATUS:two']\n",
      "Not setting metadata\n",
      "79 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Using data from preloaded Raw for 79 events and 257 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtered 79 epochs out of 79 based on reaction time threshold\n"
     ]
    }
   ],
   "source": [
    "raw_subselect = prep_raw.copy()\n",
    "raw_subselect.annotations\n",
    "\n",
    "standard_epochs = prep.get_epochs_from_events(raw_subselect, '_S')\n",
    "# deviant exemplar: a chord that is of the same function as the standard chord, but a different exemplar\n",
    "# we threshold the reaction time to 200ms as faster reactions are expected to be anticipatory\n",
    "exemplar_epochs = prep.get_epochs_from_events(raw_subselect, '_deviantEcorrect_E', min_reaction_s=0.2)\n",
    "# deviant function: a chord that is of a whole different function than the standard chord\n",
    "function_epochs = prep.get_epochs_from_events(raw_subselect, '_deviantFcorrect_F', min_reaction_s=0.2)\n",
    "\n",
    "autoreject_file = f\"./data/autoreject_info_{SUBJECT}.json\"\n",
    "\n",
    "if AUTOREJECT:\n",
    "    if os.path.exists(autoreject_file):\n",
    "        with open(autoreject_file, 'r') as f:\n",
    "            autoreject_info = json.load(f)\n",
    "\n",
    "        # apply autoreject results to save time if already computed earlier\n",
    "        standard_epochs_clean = prep.apply_autoreject_info(standard_epochs, autoreject_info['standard'])\n",
    "        exemplar_epochs_clean = prep.apply_autoreject_info(exemplar_epochs, autoreject_info['exemplar'])\n",
    "        function_epochs_clean = prep.apply_autoreject_info(function_epochs, autoreject_info['function'])\n",
    "\n",
    "    else:\n",
    "        # takes a long time!\n",
    "        ar_standard = AutoReject()\n",
    "        ar_exemplar = AutoReject()\n",
    "        ar_function = AutoReject()\n",
    "\n",
    "        # apply autoreject (takes 3-6 min)\n",
    "        autoreject_info = {}\n",
    "\n",
    "        standard_epochs_clean, reject_log_standard = ar_standard.fit_transform(standard_epochs, return_log=True)\n",
    "        autoreject_info['standard'] = {\n",
    "            'bad_epochs': reject_log_standard.bad_epochs,\n",
    "            'reject_log': reject_log_standard.labels.tolist(),\n",
    "            'threshes': ar_standard.get_reject_log(standard_epochs).threshes_\n",
    "        }\n",
    "\n",
    "        exemplar_epochs_clean, reject_log_exemplar = ar_exemplar.fit_transform(exemplar_epochs, return_log=True)\n",
    "        autoreject_info['exemplar'] = {\n",
    "            'bad_epochs': reject_log_exemplar.bad_epochs,\n",
    "            'reject_log': reject_log_exemplar.labels.tolist(),\n",
    "            'threshes': ar_exemplar.get_reject_log(exemplar_epochs).threshes_\n",
    "        }\n",
    "\n",
    "        function_epochs_clean, reject_log_function = ar_function.fit_transform(function_epochs, return_log=True)\n",
    "        autoreject_info['function'] = {\n",
    "            'bad_epochs': reject_log_function.bad_epochs,\n",
    "            'reject_log': reject_log_function.labels.tolist(),\n",
    "            'threshes': ar_function.get_reject_log(function_epochs).threshes_\n",
    "        }\n",
    "\n",
    "        # save to json per sub\n",
    "        with open(autoreject_file, \"w\") as f:\n",
    "            json.dump(autoreject_info, f, indent=4)\n",
    "else:\n",
    "    standard_epochs_clean = standard_epochs\n",
    "    exemplar_epochs_clean = exemplar_epochs\n",
    "    function_epochs_clean = function_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average forward model over the significant time intervall, using the same step and window size as in the paper\n",
    "step = 3\n",
    "window = 7\n",
    "\n",
    "# TODO: EXPLAIN list of interesting points? @Nivabo\n",
    "forward_model_exemplar = auc.generate_forward_model_sw(standard_epochs_clean.get_data(), exemplar_epochs_clean.get_data(), [36,37,38,39,40,41,42,43,44,45], window, step)\n",
    "forward_model_function = auc.generate_forward_model_sw(standard_epochs_clean.get_data(), function_epochs_clean.get_data(), [36,37,38,39,40,41,42,43,44,45], window, step)\n",
    "\n",
    "\n",
    "info = raw_subselect.info\n",
    "\n",
    "data_exemplar = forward_model_exemplar.reshape(-1, 1)\n",
    "evoked_exemplar = mne.EvokedArray(data_exemplar, info)\n",
    "evoked_exemplar.plot_topomap(times=[0], time_unit='s', ch_type='eeg')\n",
    "plt.show()\n",
    "\n",
    "data_function = forward_model_function.reshape(-1, 1)\n",
    "evoked_function = mne.EvokedArray(data_function, info)\n",
    "evoked_function.plot_topomap(times=[0], time_unit='s', ch_type='eeg')\n",
    "plt.show()\n",
    "\n",
    "# Save data\n",
    "np.savetxt(f\"./data/forward_model/forward_model_7_3_{SUBJECT}.txt\", np.column_stack((forward_model_exemplar, forward_model_function)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      2\u001b[0m window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m----> 4\u001b[0m roc_exemplar \u001b[38;5;241m=\u001b[39m \u001b[43mauc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_AUC_ROC_sliding_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandard_epochs_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexemplar_epochs_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m roc_function \u001b[38;5;241m=\u001b[39m auc\u001b[38;5;241m.\u001b[39mgenerate_AUC_ROC_sliding_window(standard_epochs_clean\u001b[38;5;241m.\u001b[39mget_data(), function_epochs_clean\u001b[38;5;241m.\u001b[39mget_data(), window, step)\n\u001b[1;32m      6\u001b[0m time \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m*\u001b[39mstep\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m128\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(roc_exemplar))]\n",
      "File \u001b[0;32m~/git/uni/eeg-chord-oddball/auc.py:405\u001b[0m, in \u001b[0;36mgenerate_AUC_ROC_sliding_window\u001b[0;34m(epoch_standard, epoch_deviant, window_length, stepsize)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# Use the leave-one-out validation\u001b[39;00m\n\u001b[1;32m    404\u001b[0m loo \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmodel_selection\u001b[38;5;241m.\u001b[39mLeaveOneOut()\n\u001b[0;32m--> 405\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassification\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassification\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# AUC\u001b[39;00m\n\u001b[1;32m    417\u001b[0m AUC_value \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mroc_auc_score(classification, scores)\n",
      "File \u001b[0;32m~/git/uni/eeg-chord-oddball/venv/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/git/uni/eeg-chord-oddball/venv/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/git/uni/eeg-chord-oddball/venv/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 3\n",
    "window = 7\n",
    "\n",
    "roc_exemplar = auc.generate_AUC_ROC_sliding_window(standard_epochs_clean.get_data(), exemplar_epochs_clean.get_data(), window, step)\n",
    "roc_function = auc.generate_AUC_ROC_sliding_window(standard_epochs_clean.get_data(), function_epochs_clean.get_data(), window, step)\n",
    "time = [i*step/128 -0.4 for i in range(len(roc_exemplar))]\n",
    "\n",
    "plt.plot(time, roc_exemplar, label=\"exemplar\")\n",
    "plt.plot(time, roc_function, label=\"function\")\n",
    "plt.axvline(-0.4, label=\"Chord 1\")\n",
    "plt.axvline(0, label=\"Chord 2\")\n",
    "plt.axvline(0.4, label=\"Chord 3\")\n",
    "plt.ylabel(\"AUC-Value\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "np.savetxt(f\"./data/auc/auc_roc_sl_7_3_{SUBJECT}.txt\", np.column_stack((roc_exemplar, roc_function)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Still relevant? @Nivabo\n",
    "\n",
    "# roc_exemplar = generate_AUC_ROC_sliding_window(standard_epochs, exemplar_epochs, window, step)\n",
    "# roc_function = generate_AUC_ROC_sliding_window(standard_epochs, function_epochs, window, step)\n",
    "# time = [i*step/128 -0.4 for i in range(len(roc_exemplar))]\n",
    "\n",
    "# plt.plot(time, roc_exemplar, label=\"exemplar\")\n",
    "# plt.plot(time, roc_function, label=\"function\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
