{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of Chord-Oddball data\n",
    "\n",
    "This notebook is used for obtaining the cleaned data and processes the raw data of the chord-oddball dataset to initiate the analysis. Guide for artifact removal (https://neuraldatascience.io/7-eeg/erp_artifacts.html).\n",
    "\n",
    "We recommend running this code with the default env values which one can retrieve from the .env.example file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from autoreject import AutoReject\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import auc\n",
    "\n",
    "from pyprep.find_noisy_channels import NoisyChannels\n",
    "\n",
    "import custom.misc as misc\n",
    "import custom.preprocessing as prep\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SUBJECT = os.getenv(\"SUBJECT\")\n",
    "BIDS_ROOT = os.getenv(\"BIDS_ROOT\")\n",
    "TASK = os.getenv(\"TASK\")\n",
    "SUBJECT = os.getenv(\"SUBJECT\")\n",
    "SUPRESS_BIDS_OUTPUT = (os.getenv('SUPRESS_BIDS_OUTPUT', 'False') == 'True')\n",
    "PROMPT_BADS = (os.getenv('PROMPT_BADS', 'False') == 'True')\n",
    "USE_ICA_JSON = (os.getenv('USE_ICA_JSON', 'False') == 'True')\n",
    "ICA_MANUAL = (os.getenv('ICA_MANUAL', 'False') == 'True')\n",
    "Z_SCORE_REJECT = (os.getenv('Z_SCORE_REJECT', 'False') == 'True')\n",
    "PYPREP_REJECT = (os.getenv('PYPREP_REJECT', 'False') == 'True')\n",
    "AUTOREJECT = (os.getenv('AUTOREJECT', 'False') == 'True')\n",
    "\n",
    "print(f\"\"\"\n",
    "      SUBJECT: {SUBJECT}\n",
    "      BIDS_ROOT: {BIDS_ROOT}\n",
    "      TASK: {TASK}\n",
    "      SUBJECT: {SUBJECT}\n",
    "      SUPRESS_BIDS_OUTPUT: {SUPRESS_BIDS_OUTPUT}\n",
    "      PROMPT_BADS: {PROMPT_BADS}\n",
    "      USE_ICA_JSON: {USE_ICA_JSON}\n",
    "      ICA_MANUAL: {ICA_MANUAL}\n",
    "      Z_SCORE_REJECT: {Z_SCORE_REJECT}\n",
    "      PYPREP_REJECT: {PYPREP_REJECT}\n",
    "      AUTOREJECT: {AUTOREJECT}\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce bids eeg data\n",
    "if not os.path.isfile(f\"./data/fifs/processed_{SUBJECT}_raw.fif\"):\n",
    "    if SUPRESS_BIDS_OUTPUT:\n",
    "        with misc.suppress_stdout_stderr():\n",
    "            raw, bids_path = misc.read_raw_data(SUBJECT)\n",
    "    else:\n",
    "        raw, bids_path = misc.read_raw_data(SUBJECT)\n",
    "        \n",
    "    channel_types = {ch: 'eeg' for ch in raw.ch_names}\n",
    "    raw.set_channel_types(channel_types)\n",
    "    \n",
    "    elec_data = pd.read_csv('./data/ds003570/sub-'+SUBJECT+'/eeg/sub-'+SUBJECT+'_task-AuditoryOddballChords_electrodes.tsv', sep='\\t')\n",
    "    # ensure that the electrode names and positions are correctly used\n",
    "    montage = mne.channels.make_dig_montage(ch_pos=dict(zip(elec_data['name'], elec_data[['x', 'y', 'z']].values)),\n",
    "                                        coord_frame='head')\n",
    "    raw.set_montage(montage)\n",
    "    blocks = prep.split_in_blocks(raw.copy())\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_channels.json\"):\n",
    "        bads = json.load(open(\"./data/bad_channels.json\"))\n",
    "        blocks = prep.set_bad_channels_from_json(blocks, bads)\n",
    "    else:\n",
    "        bads = misc.create_bad_json_structure()\n",
    "\n",
    "    if os.path.isfile(\"./data/bad_ica_components.json\"):\n",
    "        ica_bads = json.load(open(\"./data/bad_ica_components.json\"))\n",
    "    else:\n",
    "        ica_bads = misc.create_bad_json_structure()\n",
    "    \n",
    "    # deprecated, do not use\n",
    "    if Z_SCORE_REJECT == True:\n",
    "        for b in blocks:\n",
    "            # reject by z-score (autoreject is more sophisticated, but only works on epochs and is really slow)\n",
    "            b.info['bads'].extend(prep.mark_bad_channels_by_z_score(b, threshold=5.0, window_size=10000))\n",
    "            print(f\"Bad channels: {b.info['bads']}\")\n",
    "\n",
    "    if PYPREP_REJECT == True:\n",
    "        for b in blocks:\n",
    "            nc = NoisyChannels(b, random_state=42) # of course it has to be 42!\n",
    "            nc.find_all_bads(ransac=False)\n",
    "            b.info['bads'].extend(nc.get_bads())\n",
    "            print(f\"Bad channels: {b.info['bads']}\")\n",
    "\n",
    "    if PROMPT_BADS == True:\n",
    "        for b in blocks:\n",
    "            b.plot(n_channels=64)\n",
    "            plt.show(block=True)\n",
    "            bads[f\"sub-{SUBJECT}\"][f\"{blocks.index(b)+1}\"] = b.info['bads']\n",
    "    \n",
    "    \n",
    "    with open(\"./data/bad_channels.json\", \"w\") as f:\n",
    "        json.dump(bads, f)\n",
    "\n",
    "    ica_blocks = []\n",
    "\n",
    "    # separate preprocessing in 8 blocks as boundary events occured 8 times in the whole recording\n",
    "    for b in blocks:\n",
    "        b.interpolate_bads()\n",
    "        prep_block = prep.basic_preprocessing(b.copy())\n",
    "\n",
    "        # ICA\n",
    "        ica_block = prep.get_ica(prep_block, ica_bads, f\"{blocks.index(b)+1}\", montage)\n",
    "        ica_blocks.append(ica_block)\n",
    "    \n",
    "    with open(\"./data/bad_ica_components.json\", \"w\") as f:\n",
    "        json.dump(ica_bads, f)\n",
    "\n",
    "    prep_raw = mne.concatenate_raws(ica_blocks)\n",
    "    misc.save_preprocessed_data(f\"./data/fifs/processed_{SUBJECT}_raw.fif\", prep_raw)\n",
    "\n",
    "else:\n",
    "    prep_raw = mne.io.read_raw_fif(f\"./data/fifs/processed_{SUBJECT}_raw.fif\", preload=True)\n",
    "\n",
    "prep_raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_subselect = prep_raw.copy()\n",
    "raw_subselect.annotations\n",
    "\n",
    "standard_epochs = prep.get_epochs_from_events(raw_subselect, '_S')\n",
    "# deviant exemplar: a chord that is of the same function as the standard chord, but a different exemplar\n",
    "# we threshold the reaction time to 200ms as faster reactions are expected to be anticipatory\n",
    "exemplar_epochs = prep.get_epochs_from_events(raw_subselect, '_deviantEcorrect_E', min_reaction_s=0.2)\n",
    "# deviant function: a chord that is of a whole different function than the standard chord\n",
    "function_epochs = prep.get_epochs_from_events(raw_subselect, '_deviantFcorrect_F', min_reaction_s=0.2)\n",
    "\n",
    "autoreject_file = f\"./data/autoreject_info_{SUBJECT}.json\"\n",
    "\n",
    "if AUTOREJECT:\n",
    "    if os.path.exists(autoreject_file):\n",
    "        with open(autoreject_file, 'r') as f:\n",
    "            autoreject_info = json.load(f)\n",
    "\n",
    "        # apply autoreject results to save time if already computed earlier\n",
    "        standard_epochs_clean = prep.apply_autoreject_info(standard_epochs, autoreject_info['standard'])\n",
    "        exemplar_epochs_clean = prep.apply_autoreject_info(exemplar_epochs, autoreject_info['exemplar'])\n",
    "        function_epochs_clean = prep.apply_autoreject_info(function_epochs, autoreject_info['function'])\n",
    "\n",
    "    else:\n",
    "        # takes a long time!\n",
    "        ar_standard = AutoReject()\n",
    "        ar_exemplar = AutoReject()\n",
    "        ar_function = AutoReject()\n",
    "\n",
    "        # apply autoreject (takes 3-6 min)\n",
    "        autoreject_info = {}\n",
    "\n",
    "        standard_epochs_clean, reject_log_standard = ar_standard.fit_transform(standard_epochs, return_log=True)\n",
    "        autoreject_info['standard'] = {\n",
    "            'bad_epochs': reject_log_standard.bad_epochs,\n",
    "            'reject_log': reject_log_standard.labels.tolist(),\n",
    "            'threshes': ar_standard.get_reject_log(standard_epochs).threshes_\n",
    "        }\n",
    "\n",
    "        exemplar_epochs_clean, reject_log_exemplar = ar_exemplar.fit_transform(exemplar_epochs, return_log=True)\n",
    "        autoreject_info['exemplar'] = {\n",
    "            'bad_epochs': reject_log_exemplar.bad_epochs,\n",
    "            'reject_log': reject_log_exemplar.labels.tolist(),\n",
    "            'threshes': ar_exemplar.get_reject_log(exemplar_epochs).threshes_\n",
    "        }\n",
    "\n",
    "        function_epochs_clean, reject_log_function = ar_function.fit_transform(function_epochs, return_log=True)\n",
    "        autoreject_info['function'] = {\n",
    "            'bad_epochs': reject_log_function.bad_epochs,\n",
    "            'reject_log': reject_log_function.labels.tolist(),\n",
    "            'threshes': ar_function.get_reject_log(function_epochs).threshes_\n",
    "        }\n",
    "\n",
    "        # save to json per sub\n",
    "        with open(autoreject_file, \"w\") as f:\n",
    "            json.dump(autoreject_info, f, indent=4)\n",
    "else:\n",
    "    standard_epochs_clean = standard_epochs\n",
    "    exemplar_epochs_clean = exemplar_epochs\n",
    "    function_epochs_clean = function_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the AUC ROC Curve per subject, using the same step and window size as in the paper\n",
    "step = 3\n",
    "window = 7\n",
    "\n",
    "roc_exemplar = auc.generate_AUC_ROC_sliding_window(standard_epochs_clean.get_data(), exemplar_epochs_clean.get_data(), window, step)\n",
    "roc_function = auc.generate_AUC_ROC_sliding_window(standard_epochs_clean.get_data(), function_epochs_clean.get_data(), window, step)\n",
    "time = [i*step/128 -0.4 for i in range(len(roc_exemplar))]\n",
    "\n",
    "# Plot the Curve\n",
    "plt.plot(time, roc_exemplar, label=\"exemplar\")\n",
    "plt.plot(time, roc_function, label=\"function\")\n",
    "plt.axvline(-0.4, label=\"Chord 1\")\n",
    "plt.axvline(0, label=\"Chord 2\")\n",
    "plt.axvline(0.4, label=\"Chord 3\")\n",
    "plt.ylabel(\"AUC-Value\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save data\n",
    "np.savetxt(f\"./data/auc/auc_roc_sl_7_3_{SUBJECT}_TEST.txt\", np.column_stack((roc_exemplar, roc_function)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average forward model over the significant time intervall, using the same step and window size as in the paper\n",
    "step = 3\n",
    "window = 7\n",
    "\n",
    "# [36,37,38,39,40,41,42,43,44,45] are the indices of timepoints, which were found significant in statistical_analysis.ipynb\n",
    "forward_model_exemplar = auc.generate_forward_model_sw(standard_epochs_clean.get_data(), exemplar_epochs_clean.get_data(), [36,37,38,39,40,41,42,43,44,45], window, step)\n",
    "forward_model_function = auc.generate_forward_model_sw(standard_epochs_clean.get_data(), function_epochs_clean.get_data(), [36,37,38,39,40,41,42,43,44,45], window, step)\n",
    "\n",
    "\n",
    "info = raw_subselect.info\n",
    "\n",
    "data_exemplar = forward_model_exemplar.reshape(-1, 1)\n",
    "evoked_exemplar = mne.EvokedArray(data_exemplar, info)\n",
    "evoked_exemplar.plot_topomap(times=[0], time_unit='s', ch_type='eeg')\n",
    "plt.show()\n",
    "\n",
    "data_function = forward_model_function.reshape(-1, 1)\n",
    "evoked_function = mne.EvokedArray(data_function, info)\n",
    "evoked_function.plot_topomap(times=[0], time_unit='s', ch_type='eeg')\n",
    "plt.show()\n",
    "\n",
    "# Save data\n",
    "np.savetxt(f\"./data/forward_model/forward_model_7_3_{SUBJECT}_TEST.txt\", np.column_stack((forward_model_exemplar, forward_model_function)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
